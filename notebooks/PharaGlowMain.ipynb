{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pharaglow Analysis Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "%matplotlib qt\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import timeit\n",
    "from datetime import date\n",
    "# image io and analysis\n",
    "import json\n",
    "import pims\n",
    "import trackpy as tp\n",
    "\n",
    "# plotting\n",
    "import matplotlib  as mpl \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#our packages\n",
    "import pharaglow\n",
    "from pharaglow import tracking, run, features, util, io\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs the pharaglow image analysis pipeline. It comprises three stages on analysis which can be done sequentially and are independent. Analyses can be interrupted at the end of each stage after saving the output dataframe. \n",
    "\n",
    "**1. Step -  Basic object detection**\n",
    "    This step creates a \"_features.json\" file which contains a table of objects detected in each frame.\n",
    "    Beyond finding the center of mass of an object, no further image analysis is done here.\n",
    "    \n",
    "**2. Step - Linking objects into trajectories**\n",
    "    This results in individual files \"_trajectory.json\" for each tracked animal.\n",
    "    \n",
    "**3. Step - Analysing the details of object shapes**\n",
    "    This step is doing the heavy lifting: It extracts centerlines, widths, contours and other object descriptors from the objects\n",
    "\n",
    "All subsequent analyses steps add 'columns' to the data, and thus features is a subset of trajectories is a subset of results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHANGE FILE/DIRECTORY NAMES\n",
    "# parameterfile = \"../AnalysisParameters_1x\"\n",
    "# inPath = \"/home/mscholz/Dropbox (Scholz Lab)/Shared/Data/MS0006_0_1000frames\"\n",
    "# outPath = \"/home/mscholz/Desktop/TestOutput_MS0006/\"\n",
    "# lawnPath = None #\"/opt/data/Lawns/\"\n",
    "# movie = \"MS0006_0_1000frames\"\n",
    "# movieID = movie[-6:]\n",
    "# nWorkers = 5\n",
    "# chunksize = 100\n",
    "# debug=False\n",
    "\n",
    "parameterfile = \"/home/ebonnard/Desktop/Elsa/1_Rawdata/20210301_macroscope/GGE_parameters.txt\"\n",
    "inPath = \"/home/ebonnard/Desktop/Elsa/1_Rawdata/20210301_macroscope/MA0001c/\"\n",
    "outPath = \"/home/ebonnard/Desktop/Elsa/2_PharaGlow/20210301_macroscope/\"\n",
    "lawnPath = None #\"/opt/data/Lawns/\"\n",
    "movie = \"MA0001\"\n",
    "movieID = \"MA0001\"\n",
    "nWorkers = 10\n",
    "chunksize = 100\n",
    "debug=True\n",
    "\n",
    "# # Write the path of the directories where\n",
    "# # > is the parameters file\n",
    "# parameterfile = '/home/ebonnard/Desktop/Elsa/2_PharaGlow/20201217_solenoid_mutants/EB0068/Linking/EB0068_parameters.txt'\n",
    "# # > are the tiff files\n",
    "# inPath = '/home/nif/Desktop/data/Elsa/1_Rawdata/20201217_solenoid_mutants/recording/EB0068c/'\n",
    "# # > will be saved the pharaglow output files\n",
    "# outPath = f'/home/ebonnard/Desktop/Elsa/2_PharaGlow/20201217_solenoid_mutants/EB0068/broken_pharynx/'\n",
    "# # > is the tiff file with the bacterial lawn (if no lawn: None)\n",
    "# lawnPath = None #\"/opt/data/Lawns/\"\n",
    "\n",
    "# # Set the names of the tiff files folder (movie) and the identification number (movieID) of the recording\n",
    "# movie = \"EB0068\"\n",
    "# movieID = movie # the ID should be AA1000\n",
    "# # movieID = movie[-6:]\n",
    "\n",
    "# # Set the number of processing cores used for the analysis\n",
    "# nWorkers = 10\n",
    "# chunksize = 100\n",
    "\n",
    "# # Inactivate (False) or activate (True) the debug mode\n",
    "# debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today().strftime(\"%Y%m%d\")\n",
    "logger = io.log_setup('PharaGlow', 10, fname = os.path.join(outPath, f'{today}_{movieID}_pharaglow_log.txt')   )\n",
    "logging.debug('pharaglow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter file: /home/ebonnard/Desktop/Elsa/1_Rawdata/20210301_macroscope/GGE_parameters.txt\n",
      "inPath: /home/ebonnard/Desktop/Elsa/1_Rawdata/20210301_macroscope/MA0001c/\n",
      "outPath: /home/ebonnard/Desktop/Elsa/2_PharaGlow/20210301_macroscope/\n"
     ]
    }
   ],
   "source": [
    "npaths = {'parameter file': parameterfile,\n",
    "          'inPath':inPath,\n",
    "          'outPath': outPath}\n",
    "\n",
    "for key, value in npaths.items():    \n",
    "    if os.path.exists(value):\n",
    "        print(f'{key}: {value}')\n",
    "    else:\n",
    "        print(f\"Warning! The path for {key} doesnt exist: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating new file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow:output file will be saved as /home/ebonnard/Desktop/Elsa/2_PharaGlow/20210301_macroscope/MA0001_{}_{}.json\n",
      "INFO:PharaGlow:paramaters file will be saved as /home/ebonnard/Desktop/Elsa/2_PharaGlow/20210301_macroscope/MA0001_parameters\n"
     ]
    }
   ],
   "source": [
    "fname = os.path.join(inPath,\"*.tif*\")\n",
    "outfile = os.path.join(outPath, movieID+\"_{}_{}.json\")\n",
    "logger.info(f\"output file will be saved as {outfile}\")\n",
    "saveparam = os.path.join(outPath, movieID+\"_parameters\")\n",
    "logger.info(f\"paramaters file will be saved as {saveparam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:PharaGlow:Select tiff files to analyze:\n",
      "DEBUG:PharaGlow:first tiff:1, n.min:0\n",
      "DEBUG:PharaGlow:last tiff:800, n.max:799\n"
     ]
    }
   ],
   "source": [
    "if debug:\n",
    "    \n",
    "    logger.debug('Select tiff files to analyze:')\n",
    "    first_tiff = 1 # the tiff file name/number must be >= 1\n",
    "    last_tiff = 800\n",
    "\n",
    "    n = np.arange(first_tiff-1, last_tiff)  \n",
    "    logger.debug(f'first tiff:{first_tiff}, n.min:{n.min()}')\n",
    "    logger.debug(f'last tiff:{last_tiff}, n.max:{n.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load lawns if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lawnPath is not None and lawnPath != 'None':\n",
    "    logger.info('Loading lawn file...')\n",
    "    try:\n",
    "        lawnfile = os.path.join(lawnPath,movieID+'_lawn.tiff')\n",
    "        lawn = pims.open(lawnfile)[0]\n",
    "        binLawn = features.findLawn(lawn)\n",
    "    except Exception:\n",
    "        lawnfile = os.path.join(lawnPath,movieID+'_lawn.bmp')\n",
    "        lawn = pims.open(lawnfile)[0]\n",
    "        binLawn = features.findLawn(lawn)\n",
    "    logger.info(\"Lawnfile opened as 'lawn'\")\n",
    "else:\n",
    "    lawnfile = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load images and analysis parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow:Loading tiff files...\n",
      "DEBUG:PharaGlow:A subset of 800 files will be analyzed\n",
      "INFO:PharaGlow:tiff files loaded as 'rawframes'\n",
      "INFO:PharaGlow:Loading parameters from /home/ebonnard/Desktop/Elsa/1_Rawdata/20210301_macroscope/GGE_parameters.txt...\n",
      "INFO:PharaGlow:parameters file loaded as 'param':{'subtract': 1, 'smooth': 1, 'dilate': 2, 'tfactor': 1, 'thresholdWindow': 120, 'bgWindow': 100, 'length': 2, 'searchRange': 10, 'minimalDuration': 600, 'memory': 30, 'minSize': 600, 'maxSize': 1500, 'watershed': 100, 'widthStraight': 10, 'pad': 5, 'nPts': 200, 'linewidth': 2}\n",
      "INFO:PharaGlow:Loading time: 0.20721589800086804s\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "logger.info(\"Loading tiff files...\")\n",
    "rawframes = pims.open(fname)\n",
    "\n",
    "if not debug:\n",
    "    rawframes = rawframes\n",
    "if debug:\n",
    "    logger.debug(f\"A subset of {len(n)} files will be analyzed\")\n",
    "    rawframes = rawframes[n]\n",
    "logger.info(\"tiff files loaded as 'rawframes'\")\n",
    "\n",
    "\n",
    "logger.info(f\"Loading parameters from {parameterfile}...\")\n",
    "with open(parameterfile) as f:\n",
    "    param = json.load(f)\n",
    "    f.close()\n",
    "logger.info(f\"parameters file loaded as 'param':{param}\")\n",
    "\n",
    "# Measure the wall time for running the current cell [s]\n",
    "stop = timeit.default_timer()\n",
    "logger.info(f\"Loading time: {stop - start}s\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if all the tiff files have been loaded as rawframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow:Number of tiff files: 0\n",
      "INFO:PharaGlow:Number of rawframes: 800\n"
     ]
    }
   ],
   "source": [
    "nfiles = len([f for f in os.listdir(inPath) if f.endswith('tif')])\n",
    "# tiff files\n",
    "logger.info(f\"Number of tiff files: {nfiles}\")\n",
    "# rawframes \n",
    "logger.info(f\"Number of rawframes: {len(rawframes)}\")\n",
    "\n",
    "if nfiles != len(rawframes):\n",
    "    if not debug:\n",
    "        logger.warning(\"the number of tiff files doesn't match with the number of rawframes !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve lawn detection if neccessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lawnfile is not None:\n",
    "    from skimage.filters import threshold_li, gaussian, threshold_yen, threshold_otsu\n",
    "    from skimage.morphology import skeletonize, watershed, disk, remove_small_holes, remove_small_objects\n",
    "    image = gaussian(lawn, 1, preserve_range = True)\n",
    "    thresh = threshold_li(image, initial_guess = np.median)\n",
    "    binary = image > thresh*0.5\n",
    "    binary = remove_small_holes(binary, area_threshold=1500, connectivity=1, in_place=False)\n",
    "    binary = remove_small_objects(binary, min_size=5000, connectivity=8, in_place=False)\n",
    "    binLawn = binary\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(lawn)\n",
    "    plt.contour(binLawn, alpha=0.5, cmap='pink')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(binLawn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create binary masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:PharaGlow:parameter tfactor changed to 1\n"
     ]
    }
   ],
   "source": [
    "## To quickly adjust the parameters\n",
    "# param['bgWindow']=71\n",
    "# logger.debug(f\"parameter bgWindow changed to {param['bgWindow']}\")\n",
    "\n",
    "# param['thresholdWindow']=111\n",
    "# logger.debug(f\"parameter thresholdWindow changed to {param['thresholdWindow']}\")\n",
    "\n",
    "# param['smooth']=1\n",
    "# logger.debug(f\"parameter smooth changed to {param['smooth']}\")\n",
    "\n",
    "# param['dilate']=2\n",
    "# logger.debug(f\"parameter dilate changed to {param['dilate']}\")\n",
    "\n",
    "# param['tfactor'] = 1\n",
    "# logger.debug(f\"parameter tfactor changed to {param['tfactor']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow:Binarizing images...\n",
      "INFO:PharaGlow:binary masks created (3.3504359490034403s)\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "# detecting objects\n",
    "logger.info('Binarizing images...')\n",
    "\n",
    "masks = tracking.calculateMask(rawframes,\n",
    "                               minSize = param['minSize'],\n",
    "                               bgWindow = param['bgWindow'],\n",
    "                               thresholdWindow = param['thresholdWindow'],\n",
    "                               smooth =  param['smooth'],\n",
    "                               subtract =  param['subtract'],\n",
    "                               dilate = param['dilate'],\n",
    "                               tfactor=param['tfactor'])\n",
    "\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "logger.info(f\"binary masks created ({stop - start}s)\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure the thresholding worked otherwise change parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rawframe 539 (or tiff 540) to visualize\n"
     ]
    }
   ],
   "source": [
    "# Select a rawframe to visualize\n",
    "t = 539\n",
    "\n",
    "if t> (len(rawframes)-1):\n",
    "    # Check if the selected rawframe is present otherwise select the first frame\n",
    "    print(f\"Warning ! Max {len(rawframes)-1} rawframes. {t} changed to 0\")\n",
    "    t=0\n",
    "\n",
    "if debug:\n",
    "    if first_tiff:\n",
    "        print(f\"rawframe {t} (or tiff {first_tiff+t}) to visualize\")      \n",
    "else:\n",
    "    print(f\"rawframe {t} to visualize \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.subplot(121)\n",
    "# Plot the histogram of the pixel intensity values of the rawframe\n",
    "plt.hist(rawframes[t].ravel(), bins=256, log=True)\n",
    "plt.xlim(0, 260) # xlim for 8 bits image\n",
    "\n",
    "plt.subplot(122)\n",
    "# Adjust the color limit for a better vizualisation of the rawframe\n",
    "# color = (0,150) # 0<=color<=255 for 8 bits image\n",
    "color = None \n",
    "plt.imshow(rawframes[t],clim = color)\n",
    "plt.colorbar(orientation='horizontal');\n",
    "\n",
    "# plt.savefig(os.path.join(outPath,f'{today}_{movieID}_px_hist_{t}.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show the mask and detected objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 detected objects\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib qt\n",
    "\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "plt.figure(figsize=(18,14))\n",
    "plt.subplot(121)\n",
    "# Show the rawframe\n",
    "plt.imshow(rawframes[t],clim= color)#+lawn)\n",
    "if lawnfile is not None:\n",
    "    # Show the lawn\n",
    "    plt.contour(binLawn, alpha=0.5, cmap='pink')\n",
    "    \n",
    "plt.subplot(122)\n",
    "# Show the masks and their size [px]\n",
    "plt.imshow(masks[t])#[:600,1000:])#[500:1500,2000:3500])#[:,2500:])\n",
    "# print(np.min(masks[t]))\n",
    "label_image, num = label(masks[t], background=0, connectivity = 1,return_num=True)\n",
    "print(f\"{num} detected objects\")\n",
    "for region in regionprops(label_image):\n",
    "    plt.text(region.centroid[1]+50, region.centroid[0], region.area, color ='w')\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "# if not debug:\n",
    "#     plt.title(f\"Rawframe and masks (#{num}) at t={t} ({movieID})\",fontsize=24)\n",
    "#     plt.savefig(os.path.join(outPath,f'{today}_{movieID}_masks_rawframe{t}.pdf'))\n",
    "if debug:\n",
    "    plt.title(f\"Rawframe and masks (#{num}) at {t} (tiff {first_tiff+t}) ({movieID})\", fontsize=24)\n",
    "    plt.savefig(os.path.join(outPath,f'{today}_{movieID}_masks_tiff{first_tiff+t}.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting individual objects and tracking or use multiprocessing to speed up feature detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow:chunksize=100\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'chunksize={chunksize}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:PharaGlow:parameter maxSize changed to 2000\n",
      "DEBUG:PharaGlow:parameter watershed changed to 20\n"
     ]
    }
   ],
   "source": [
    "# param['maxSize']=2000 #1500  2000  1800  1900\n",
    "# logger.debug(f\"parameter maxSize changed to {param['maxSize']}\")\n",
    "\n",
    "# param['watershed'] = 20 # 100  70  20\n",
    "# logger.debug(f\"parameter watershed changed to {param['watershed']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow:Detecting features...\n",
      "INFO:PharaGlow:...with parallel detection...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing frames 0 to 100\n",
      "Analyzing frames 100 to 200\n",
      "Analyzing frames 200 to 300\n",
      "Analyzing frames 300 to 400\n",
      "Analyzing frames 400 to 500\n",
      "Analyzing frames 500 to 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/skimage/filters/thresholding.py:638: RuntimeWarning: divide by zero encountered in log\n",
      "  (np.log(mean_back) - np.log(mean_fore)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing frames 600 to 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/skimage/filters/thresholding.py:638: RuntimeWarning: divide by zero encountered in log\n",
      "  (np.log(mean_back) - np.log(mean_fore)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing frames 700 to 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow:features detected (306.55987730300694s)\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "logger.info('Detecting features...')\n",
    "\n",
    "if nWorkers ==1 or len(rawframes) < chunksize:\n",
    "    logger.info('...without parallel detection...')\n",
    "    features, images = tracking.runfeatureDetection(rawframes, masks, param, frameOffset = 0)\n",
    "    images.columns = [f\"im{s}\" for s in images.columns]\n",
    "    features = pd.concat([features, images], axis = 1)\n",
    "else:\n",
    "    logger.info('...with parallel detection...')\n",
    "    features = tracking.parallelDetection(rawframes, masks, param, nWorkers, chunksize)\n",
    "    \n",
    "\n",
    "stop = timeit.default_timer()\n",
    "logger.info(f\"features detected ({stop - start}s)\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow: Number of frames in features:800\n"
     ]
    }
   ],
   "source": [
    "# Files monitoring\n",
    "logger.info(f\" Number of frames in features:{features['frame'].nunique()}\")\n",
    "                                                       \n",
    "if len(rawframes) != len(features['frame'].unique()):\n",
    "    logger.warning(f\" Number of frames in features ({features['frame'].nunique()}) and the number of rawframes ({len(rawframes)}) don't match !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize results of object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow:features.area.min():451\n",
      "INFO:PharaGlow:features.area.max():1936\n"
     ]
    }
   ],
   "source": [
    "### Show the area of all objects\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "features['area'].hist(bins = 30)\n",
    "plt.xlabel('Area (px)')\n",
    "plt.subplot(122)\n",
    "features['frame'].value_counts().sort_index().plot()\n",
    "plt.ylabel('Number of objects')\n",
    "plt.xlabel('Frame')\n",
    "#features['frame'].hist(bins = len(rawframes))\n",
    "\n",
    "logger.info(f\"features.area.min():{features.area.min()}\") # region.area > params['minSize']\n",
    "logger.info(f\"features.area.max():{features.area.max()}\") # region.a#     t=30rea < params['maxSize'] \n",
    "\n",
    "plt.savefig(os.path.join(outPath,f'{today}_{movieID}_features_objects.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow:Saving features...\n",
      "INFO:PharaGlow:features saved as /home/ebonnard/Desktop/Elsa/2_PharaGlow/20210301_macroscope/MA0001_features_all.json (1.249721532993135s)\n",
      "INFO:PharaGlow:Saving parameters...\n",
      "INFO:PharaGlow:parameters saved as /home/ebonnard/Desktop/Elsa/1_Rawdata/20210301_macroscope/GGE_parameters.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2316 entries, 0 to 2315\n",
      "Columns: 5487 entries, y to im5474\n",
      "dtypes: float64(579), int64(8), uint8(4900)\n",
      "memory usage: 21.2 MB\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "# saving features\n",
    "logger.info(\"Saving features...\")\n",
    "features.info(memory_usage='deep')\n",
    "features.to_json(outfile.format('features', 'all'), orient='split')\n",
    "stop = timeit.default_timer()\n",
    "logger.info(f\"features saved as {outfile.format('features', 'all')} ({stop - start}s)\")\n",
    "\n",
    "# saving parameter file\n",
    "logger.info(\"Saving parameters...\")\n",
    "shutil.copyfile(parameterfile, saveparam, follow_symlinks=True)\n",
    "logger.info(f\"parameters saved as {parameterfile}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Load features if continuing prior analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time  \n",
    "# # Load feature\n",
    "# start = timeit.default_timer()\n",
    "# logger.info(\"Loading features...\")\n",
    "# features = io.load(outfile.format('features', 'all'), orient='split')\n",
    "# features.info()\n",
    "# stop = timeit.default_timer()\n",
    "# logger.info(f\"features loaded ({stop - start}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link objects to trajectories using trackpy and interpolate short misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow:Linking trajectories...\n",
      "INFO:PharaGlow:Parameter searchRange: 10 px\n",
      "INFO:PharaGlow:Parameter memory: 30 frames\n"
     ]
    }
   ],
   "source": [
    "logger.info('Linking trajectories...')\n",
    "logger.info(f\"Parameter searchRange: {param['searchRange']} px\")\n",
    "logger.info(f\"Parameter memory: {param['memory']} frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow:Number of trajectories after linking: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 799: 4 trajectories present.\n"
     ]
    }
   ],
   "source": [
    "#pred = tp.predict.NearestVelocityPredict()\n",
    "#trajectories = pred.link_df(features,param['searchRange'], memory = param['memory'])\n",
    "trajectories = tp.link_df(features,param['searchRange'], memory = param['memory'])\n",
    "logger.info(f\"Number of trajectories after linking: {len(trajectories['particle'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the variable features to save memory\n",
    "del features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    plt.figure(figsize=(8,8))\n",
    "    tp.plot_traj(trajectories, colorby = 'particle', superimpose=1-masks[t],label=False)\n",
    "    plt.savefig(os.path.join(outPath,f'{today}_{movieID}_trajectories_after_linking.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow:Interpolating trajectories...\n",
      "INFO:PharaGlow:Interpolation done.\n"
     ]
    }
   ],
   "source": [
    "logger.info('Interpolating trajectories...')\n",
    "\n",
    "traj = []\n",
    "\n",
    "for particle_index in trajectories['particle'].unique():\n",
    "    tmp = trajectories[trajectories.loc[:,'particle'] == particle_index]\n",
    "    # interpolate data but do not interpolate the images!\n",
    "    tmp = tracking.interpolateTrajectories(tmp, columns = ['x', 'y', 'shapeX', 'shapeY', 'particle'])\n",
    "    # replace nans again and convert images to uints8\n",
    "    imcols = [col for col in tmp.columns if \"im\" in str(col)]\n",
    "    tmp[imcols] = tmp[imcols].fillna(0).astype('uint8')\n",
    "    traj.append(tmp)\n",
    "trajectories = pd.concat(traj, ignore_index = True)\n",
    "trajectories['shapeX'] = trajectories['shapeX'].astype(int)\n",
    "trajectories['shapeY'] = trajectories['shapeY'].astype(int)\n",
    "\n",
    "logger.info(f\"Interpolation done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    plt.figure(figsize=(8,8))\n",
    "    tp.plot_traj(trajectories, colorby = 'particle', superimpose=1-masks[t],label=False)\n",
    "    plt.savefig(os.path.join(outPath,f'{today}_{movieID}_trajectories_after_interpolation.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param['minimalDuration'] = 60 # 900\n",
    "# logger.debug(f\"parameter minimalDuration changed to {param['minimalDuration']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow:Filtering out trajectories which last less than the minimal duration (600 frames)...\n",
      "INFO:PharaGlow:Nb of trajectories before filtering: 10\n",
      "INFO:PharaGlow:Nb of trajectories after filtering: 2\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Filtering out trajectories which last less than the minimal duration ({param['minimalDuration']} frames)...\")\n",
    "logger.info(f\"Nb of trajectories before filtering: {trajectories['particle'].nunique()}\")\n",
    "\n",
    "trajectories = tp.filter_stubs(trajectories,param['minimalDuration'])\n",
    "logger.info(f\"Nb of trajectories after filtering: {trajectories['particle'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract lawn info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inside(x,y,binLawn):\n",
    "    return binLawn[int(y), int(x)]\n",
    "\n",
    "if lawnfile is not None:\n",
    "    trajectories['inside'] = trajectories.apply(\\\n",
    "        lambda row: pd.Series(inside(row['x'], row['y'], binLawn)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show resulting trajectories\n"
     ]
    }
   ],
   "source": [
    "if debug:\n",
    "    print(\"Show resulting trajectories\")\n",
    "    plt.figure(figsize=(11,11))\n",
    "    plt.title(f\"{trajectories['particle'].nunique()} trajectories detected ({movieID})\")\n",
    "    tp.plot_traj(trajectories)\n",
    "    # tp.plot_traj(trajectories, superimpose=1-masks[t], label=False)\n",
    "\n",
    "    plt.savefig(os.path.join(outPath,f'{today}_{movieID}_resulting_trajectories.pdf'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save individual trajectories & add the missing images to interpolated trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow:Saving 2 trajectories to separate files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating 493.0\n",
      "interpolating 496.0\n",
      "interpolating 500.0\n",
      "interpolating 501.0\n",
      "interpolating 502.0\n",
      "interpolating 503.0\n",
      "interpolating 505.0\n",
      "interpolating 507.0\n",
      "interpolating 508.0\n",
      "interpolating 509.0\n",
      "interpolating 510.0\n",
      "interpolating 512.0\n",
      "interpolating 513.0\n",
      "interpolating 514.0\n",
      "interpolating 515.0\n",
      "interpolating 516.0\n",
      "interpolating 520.0\n",
      "interpolating 521.0\n",
      "interpolating 523.0\n",
      "interpolating 526.0\n",
      "interpolating 528.0\n",
      "interpolating 530.0\n",
      "interpolating 534.0\n",
      "interpolating 535.0\n",
      "interpolating 536.0\n",
      "interpolating 537.0\n",
      "interpolating 538.0\n",
      "interpolating 539.0\n",
      "interpolating 540.0\n",
      "interpolating 541.0\n",
      "interpolating 542.0\n",
      "interpolating 544.0\n",
      "interpolating 545.0\n",
      "interpolating 549.0\n",
      "interpolating 550.0\n",
      "interpolating 552.0\n",
      "interpolating 553.0\n",
      "interpolating 557.0\n",
      "interpolating 558.0\n",
      "interpolating 561.0\n",
      "interpolating 562.0\n",
      "interpolating 564.0\n",
      "interpolating 565.0\n",
      "interpolating 566.0\n",
      "interpolating 567.0\n",
      "interpolating 568.0\n",
      "interpolating 569.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow:trajectories saved as json files (32.888778225998976s)\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "# # write trajectories to separate files.\n",
    "\n",
    "logger.info(f\"Saving {trajectories['particle'].nunique()} trajectories to separate files...\")\n",
    "\n",
    "for particle_index in trajectories['particle'].unique():\n",
    "    tmp = trajectories[trajectories.loc[:,'particle'] == particle_index]\n",
    "    # fill missing images now\n",
    "    tmp = tmp.apply(\\\n",
    "    lambda row: tracking.interpolate_helper(rawframes, row, param), axis=1)\n",
    "    # replace nans again and convert images to uints8\n",
    "    imcols = [col for col in tmp.columns if \"im\" in str(col)]\n",
    "    tmp[imcols] = tmp[imcols].fillna(0).astype('uint8')\n",
    "    # write trajectories to file\n",
    "    tmp.to_json(outfile.format('trajectories', int(particle_index)), orient='split')\n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "logger.info(f\"trajectories saved as json files ({stop - start}s)\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check slow-down before continuing analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lawnfile is not None:\n",
    "    plt.figure(figsize=(12,8))\n",
    "    vcut = []\n",
    "    dt = 1000\n",
    "    for pid in trajectories['particle'].unique():\n",
    "        tmp = trajectories[['frame', 'x', 'y']][trajectories.loc[:,'particle'] == pid].diff()\n",
    "        f = (trajectories[['inside']][trajectories.loc[:,'particle'] == pid]).mean().values\n",
    "        if f<0.9 and f>0.01:\n",
    "            t0 = np.where((trajectories[['inside']][trajectories.loc[:,'particle'] == pid])==1)[0][0]\n",
    "            print('t0:', t0)\n",
    "            try:\n",
    "                if t0>dt:\n",
    "                    print('pid:', pid)\n",
    "                    time = np.linspace(0,2*dt/30., 2*dt)\n",
    "                    #print('time:', len(time))\n",
    "                    v = np.sqrt((tmp['x']**2+tmp['y']**2))/tmp['frame']*30*2.4\n",
    "                    #print('v:', v)\n",
    "                    #print('v.iloc:', v.iloc[t0-dt:t0+dt])\n",
    "                    plt.plot(time, v.iloc[t0-dt:t0+dt], 'navy', alpha=0.1)\n",
    "                    vcut.append(v.iloc[t0-dt:t0+dt].values)\n",
    "                else:\n",
    "                    print('trajectory is too short')\n",
    "            except ValueError:\n",
    "                print('t0-dt or t0+dt exceeds number of frames')\n",
    "                continue\n",
    "                    \n",
    "    if len(vcut) >0:  \n",
    "        plt.plot(time, np.mean(np.array(vcut), axis=0), color='navy')\n",
    "        plt.plot(time, util.smooth(np.mean(np.array(vcut), axis=0), 30), color='r')\n",
    "        plt.axvline(dt/30, color='k', linestyle='--')\n",
    "        plt.ylabel(r\"velocity ($\\mu$m/s)\");\n",
    "        plt.xlabel(\"time (s)\");\n",
    "        plt.ylim(0,150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the whole pharaglow feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing trajectory: MA0001_trajectories_1.json\n",
      "[62, 62, 62, 62, 62, 62, 62, 61, 61, 61]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/skimage/filters/thresholding.py:638: RuntimeWarning: divide by zero encountered in log\n",
      "  (np.log(mean_back) - np.log(mean_fore)))\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/skimage/filters/thresholding.py:638: RuntimeWarning: divide by zero encountered in log\n",
      "  (np.log(mean_back) - np.log(mean_fore)))\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/skimage/filters/thresholding.py:638: RuntimeWarning: divide by zero encountered in log\n",
      "  (np.log(mean_back) - np.log(mean_fore)))\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/skimage/filters/thresholding.py:638: RuntimeWarning: divide by zero encountered in log\n",
      "  (np.log(mean_back) - np.log(mean_fore)))\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing trajectory: MA0001_trajectories_0.json\n",
      "[80, 80, 80, 80, 80, 80, 80, 80, 80, 80]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/skimage/filters/thresholding.py:638: RuntimeWarning: divide by zero encountered in log\n",
      "  (np.log(mean_back) - np.log(mean_fore)))\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/skimage/filters/thresholding.py:638: RuntimeWarning: divide by zero encountered in log\n",
      "  (np.log(mean_back) - np.log(mean_fore)))\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/opt/anaconda/envs/pumping/lib/python3.7/site-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "INFO:PharaGlow:minimal information saved\n",
      "INFO:PharaGlow:Whole pharaglow features extracted (122.68915329698939s)\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "# save only minimal outputs - reduces save by approx factor 3\n",
    "save_minimal = True\n",
    "path = os.path.dirname(outfile)\n",
    "\n",
    "for fn in os.listdir(path):\n",
    "    file = os.path.join(path,fn)\n",
    "    if os.path.isfile(file) and f'{movieID}_trajectories_' in fn and fn.endswith('.json'):\n",
    "        particle_index = int(fn.split('.')[0].split('_')[-1])\n",
    "        traj =  io.load(file, orient='split')\n",
    "        # create a temporary column with an image array\n",
    "        traj['image'] = traj.apply(lambda row: util.get_im(row, [f'im{i}' for i in range(int(row['shapeX'])*int(row['shapeY']))],\n",
    "                                            int(row['shapeX'])), axis=1)\n",
    "        \n",
    "        # skip invalid frames\n",
    "        invalid_images = traj[[np.sum(im)==0 for im in traj['image']]].index\n",
    "        if len(invalid_images)>0:\n",
    "            logger.info(f'invalid images in frames {invalid_images}')\n",
    "        # ignore rows where images are empty - we later will interpolate\n",
    "        traj = traj.drop(invalid_images)\n",
    "        if len(traj.index)<1:\n",
    "            print('Skipped', file)\n",
    "            continue\n",
    "        traj['shapeX'] = traj['shapeX'].astype(int)\n",
    "        print('Analyzing trajectory:', fn)\n",
    "        tmp = util.parallelize_dataframe(traj, run.runPharaglowOnStack, n_cores = nWorkers, params = param)\n",
    "        \n",
    "        # get more exact entry location\n",
    "        if lawnfile is not None:\n",
    "            tmp['insideHead'] = tmp.apply(\\\n",
    "                lambda row: pd.Series(features.headLocationLawn(row['Centerline'],(row['slice_y0'], row['slice_x0']), binLawn)), axis=1)\n",
    "            tmp['insideHeadIntensity'] = tmp.apply(\\\n",
    "                lambda row: pd.Series(features.headLocationLawn(row['Centerline'],(row['slice_y0'], row['slice_x0']), lawn)), axis=1)\n",
    "        \n",
    "        # remove some columns to make the result smaller\n",
    "        if save_minimal:\n",
    "            tmp = tmp.drop(['Mask', 'SkeletonX', 'SkeletonY', 'ParX', 'ParY', \n",
    "                            'Xstart', 'Xend', 'Centerline', 'dCl', 'Widths', 'Contour', 'Gradient', \n",
    "                            'Kymo', 'KymoGrad', 'Similarity', 'Xtmp'], axis = 1)\n",
    "        \n",
    "        tmp = tmp.drop(['image'], axis = 1)\n",
    "        tmp.to_json(outfile.format('results', particle_index), orient='split')\n",
    "\n",
    "if save_minimal:\n",
    "    logger.info('minimal information saved')\n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "logger.info(f\"Whole pharaglow features extracted ({stop - start}s)\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if data has been analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow:trajectories.json files: 2 \n",
      "INFO:PharaGlow:results.json files: 2 \n"
     ]
    }
   ],
   "source": [
    "# Files monitoring\n",
    "\n",
    "files_list = os.listdir(outPath)\n",
    "f1 =[]\n",
    "f2 =[]\n",
    "\n",
    "for fn in files_list:\n",
    "    file = os.path.join(outPath,fn)\n",
    "    if os.path.isfile(file) and f'{movieID}_trajectories_' in fn  and fn.endswith('.json'):\n",
    "        if not 'all' in fn: \n",
    "            particle_index = int(fn.split('.')[0].split('_')[-1])\n",
    "            f1.append(particle_index)\n",
    "    if os.path.isfile(file) and f'{movieID}_results_' in fn and fn.endswith('.json'): \n",
    "        particle_index = int(fn.split('.')[0].split('_')[-1])\n",
    "        f2.append(particle_index)\n",
    "\n",
    "\n",
    "logger.info('trajectories.json files: %s ', len(f1))\n",
    "logger.info('results.json files: %s ', len(f2))\n",
    "if len(f1) != len(f2):\n",
    "    logger.warning('trajectories - results: %s', set(f1).symmetric_difference(set(f2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:PharaGlow:New parameters:{'subtract': 1, 'smooth': 1, 'dilate': 2, 'tfactor': 1, 'thresholdWindow': 120, 'bgWindow': 100, 'length': 2, 'searchRange': 10, 'minimalDuration': 600, 'memory': 30, 'minSize': 600, 'maxSize': 2000, 'watershed': 20, 'widthStraight': 10, 'pad': 5, 'nPts': 200, 'linewidth': 2}\n",
      "DEBUG:PharaGlow:New parameters saved as /home/ebonnard/Desktop/Elsa/2_PharaGlow/20210301_macroscope/MA0001_parameters_new.txt\n"
     ]
    }
   ],
   "source": [
    "# Saving parameters if they have been changed (debug mode activated)\n",
    "if debug:\n",
    "    logger.debug(f\"New parameters:{param}\")\n",
    "    paramPath = os.path.join(outPath, movieID + '_parameters_new.txt')\n",
    "    with open(paramPath,'w') as f:\n",
    "         f.write(json.dumps(param)) # use `json.loads` to do the reverse\n",
    "         \n",
    "    logger.debug(f\"New parameters saved as {paramPath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PharaGlow:PharaGlow ends here\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"PharaGlow ends here\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
