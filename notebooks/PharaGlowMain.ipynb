{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pharaglow Analysis Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import timeit\n",
    "from datetime import date\n",
    "# image io and analysis\n",
    "import json\n",
    "import pims\n",
    "from skimage.io import imsave\n",
    "import trackpy as tp\n",
    "\n",
    "# plotting\n",
    "import matplotlib  as mpl \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#our packages\n",
    "import pharaglow\n",
    "from pharaglow import tracking, run, features, util, io, extract\n",
    "\n",
    "# show logger messabes loally\n",
    "import logging\n",
    "logging.debug('pharaglow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs the pharaglow image analysis pipeline. It comprises three stages on analysis which can be done sequentially and are independent. Analyses can be interrupted at the end of each stage after saving the output dataframe. \n",
    "\n",
    "**1. Step -  Basic object detection**\n",
    "    This step creates a \"_features.json\" file which contains a table of objects detected in each frame.\n",
    "    Beyond finding the center of mass of an object, no further image analysis is done here.\n",
    "    \n",
    "**2. Step - Linking objects into trajectories**\n",
    "    This results in individual files \"_trajectory.json\" for each tracked animal.\n",
    "    \n",
    "**3. Step - Analysing the details of object shapes**\n",
    "    This step is doing the heavy lifting: It extracts centerlines, widths, contours and other object descriptors from the objects\n",
    "\n",
    "All subsequent analyses steps add 'columns' to the data, and thus features is a subset of trajectories is a subset of results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterfile = \"../AnalysisParameters_1x\"\n",
    "inPath = \"/home/mscholz/Dropbox (Scholz Lab)/Shared/Data/MS0006_0_1000frames\"\n",
    "outPath = \"/home/mscholz/Desktop/TestOutput_MS0006/\"\n",
    "lawnPath = None #\"/opt/data/Lawns/\"\n",
    "movie = \"MS0006_0_1000frames\"\n",
    "movieID = movie[-6:]\n",
    "nWorkers = 5\n",
    "nWorkers = 10\n",
    "chunksize = 100\n",
    "debug=False\n",
    "\n",
    "parameterfile = \"/opt/data/Elsa/2_PharaGlow/20201217_solenoid_mutants/EB0068/20212004_new_pg_test/20210221_EB0068_parameters.txt\"\n",
    "inPath = \"/opt/data/Elsa/1_Rawdata/20201217_solenoid_mutants/recording/EB0068c\"\n",
    "outPath = \"/opt/data/Elsa/2_PharaGlow/20201217_solenoid_mutants/EB0068/20212004_new_pg_test\"\n",
    "lawnPath = None #\"/opt/data/Lawns/\"\n",
    "movie = \"EB0068c\"\n",
    "movieID = movie[:-1]\n",
    "nWorkers = 10\n",
    "chunksize = 100\n",
    "debug=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# # Write the path of the directories where\n",
    "# # > is the parameters file\n",
    "# parameterfile = '/home/ebonnard/Desktop/Elsa/2_PharaGlow/20201217_solenoid_mutants/EB0068/Linking/EB0068_parameters.txt'\n",
    "# # > are the tiff files\n",
    "# inPath = '/home/nif/Desktop/data/Elsa/1_Rawdata/20201217_solenoid_mutants/recording/EB0068c/'\n",
    "# # > will be saved the pharaglow output files\n",
    "# outPath = f'/home/ebonnard/Desktop/Elsa/2_PharaGlow/20201217_solenoid_mutants/EB0068/broken_pharynx/'\n",
    "# # > is the tiff file with the bacterial lawn (if no lawn: None)\n",
    "# lawnPath = None #\"/opt/data/Lawns/\"\n",
    "\n",
    "# # Set the names of the tiff files folder (movie) and the identification number (movieID) of the recording\n",
    "# movie = \"EB0068\"\n",
    "# movieID = movie # the ID should be AA1000\n",
    "# # movieID = movie[-6:]\n",
    "\n",
    "# # Set the number of processing cores used for the analysis\n",
    "# nWorkers = 10\n",
    "# chunksize = 100\n",
    "\n",
    "# # Inactivate (False) or activate (True) the debug mode\n",
    "# debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today().strftime(\"%Y%m%d\")\n",
    "logger = io.log_setup('PharaGlow', 10, fname = os.path.join(outPath, f'{today}_{movieID}_pharaglow_log.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npaths = {'parameter file': parameterfile,\n",
    "          'inPath':inPath,\n",
    "          'outPath': outPath}\n",
    "\n",
    "for key, value in npaths.items():    \n",
    "    if os.path.exists(value):\n",
    "        print(f'{key}: {value}')\n",
    "    else:\n",
    "        print(f\"Warning! The path for {key} doesnt exist: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating new file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(inPath,\"*.tif*\")\n",
    "outfile = os.path.join(outPath, movieID+\"_{}_{}.json\")\n",
    "imfile =  os.path.join(outPath, movieID+\"_{}_{}.tiff\")\n",
    "logger.info(f\"output file will be saved as {outfile}\")\n",
    "logger.info(f\"output file will be saved as {imfile}\")\n",
    "saveparam = os.path.join(outPath, movieID+\"_parameters\")\n",
    "logger.info(f\"parameters file will be saved as {saveparam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    logger.debug('Select tiff files to analyze:')\n",
    "    first_tiff = 6000 # tiff file identification number (minimum=1))\n",
    "    last_tiff = 7200\n",
    "\n",
    "    n = np.arange(first_tiff-1, last_tiff)  \n",
    "    logger.debug(f'first tiff:{first_tiff}, n.min:{n.min()}')\n",
    "    logger.debug(f'last tiff:{last_tiff}, n.max:{n.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load lawns if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lawnPath is not None and lawnPath != 'None':\n",
    "    logger.info('Loading lawn file...')\n",
    "    try:\n",
    "        lawnfile = os.path.join(lawnPath,movieID+'_lawn.tiff')\n",
    "        lawn = pims.open(lawnfile)[0]\n",
    "        binLawn = features.findLawn(lawn)\n",
    "    except Exception:\n",
    "        lawnfile = os.path.join(lawnPath,movieID+'_lawn.bmp')\n",
    "        lawn = pims.open(lawnfile)[0]\n",
    "        binLawn = features.findLawn(lawn)\n",
    "    logger.info(\"Lawnfile opened as 'lawn'\")\n",
    "else:\n",
    "    lawnfile = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load images and analysis parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "logger.info(\"Loading tiff files...\")\n",
    "rawframes = pims.open(fname)\n",
    "\n",
    "if not debug:\n",
    "    rawframes = rawframes\n",
    "if debug:\n",
    "    logger.debug(f\"A subset of {len(n)} files will be analyzed\")\n",
    "    rawframes = rawframes[n]\n",
    "logger.info(\"tiff files loaded as 'rawframes'\")\n",
    "\n",
    "\n",
    "logger.info(f\"Loading parameters from {parameterfile}...\")\n",
    "with open(parameterfile) as f:\n",
    "    param = json.load(f)\n",
    "    f.close()\n",
    "logger.info(f\"parameters file loaded as 'param':{param}\")\n",
    "\n",
    "# Measure the wall time for running the current cell [s]\n",
    "stop = timeit.default_timer()\n",
    "logger.info(f\"Loading time: {stop - start}s\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if all the tiff files have been loaded as rawframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfiles = len([f for f in os.listdir(inPath) if '.tif' in f])\n",
    "# tiff files\n",
    "logger.info(f\"Number of tiff files: {nfiles}\")\n",
    "# rawframes \n",
    "logger.info(f\"Number of rawframes: {len(rawframes)}\")\n",
    "\n",
    "if nfiles != len(rawframes):\n",
    "    if not debug:\n",
    "        logger.warning(\"the number of tiff files doesn't match with the number of rawframes !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve lawn detection if neccessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lawnfile is not None:\n",
    "    from skimage.filters import threshold_li, gaussian, threshold_yen, threshold_otsu\n",
    "    from skimage.morphology import skeletonize, watershed, disk, remove_small_holes, remove_small_objects\n",
    "    image = gaussian(lawn, 1, preserve_range = True)\n",
    "    thresh = threshold_li(image, initial_guess = np.median)\n",
    "    binary = image > thresh*0.5\n",
    "    binary = remove_small_holes(binary, area_threshold=1500, connectivity=1, in_place=False)\n",
    "    binary = remove_small_objects(binary, min_size=5000, connectivity=8, in_place=False)\n",
    "    binLawn = binary\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(lawn)\n",
    "    plt.contour(binLawn, alpha=0.5, cmap='pink')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(binLawn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create binary masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param['bgWindow']=111\n",
    "# logger.debug(f\"parameter bgWindow changed to {param['bgWindow']}\")\n",
    "\n",
    "# param['thresholdWindow']=511\n",
    "# logger.debug(f\"parameters thresholdWindow changed to {param['thresholdWindow']}\")\n",
    "\n",
    "# param['tfactor'] = 0.65\n",
    "# logger.debug(f\"parameters tfactor changed to {param['tfactor']}\")\n",
    "\n",
    "# param['smooth']=1\n",
    "# logger.debug(f\"parameters smooth changed to {param['smooth']}\")\n",
    "\n",
    "# param['dilate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "# detecting objects\n",
    "logger.info('Binarizing images...')\n",
    "\n",
    "masks = tracking.calculateMask(rawframes,\n",
    "                               minSize = param['minSize'],\n",
    "                               bgWindow = param['bgWindow'],\n",
    "                               thresholdWindow = param['thresholdWindow'],\n",
    "                               smooth =  param['smooth'],\n",
    "                               subtract =  param['subtract'],\n",
    "                               dilate = param['dilate'],\n",
    "                               tfactor=param['tfactor'])\n",
    "\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "logger.info(f\"binary masks created ({stop - start}s)\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure the thresholding worked otherwise change parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a rawframe to visualize\n",
    "t = 5400 \n",
    "\n",
    "if t> (len(rawframes)-1):\n",
    "    # Check if the selected rawframe is present otherwise t=0\n",
    "    print(f\"Warning ! Max {len(rawframes)} rawframes. {t} changed to 0\")\n",
    "    t=0\n",
    "\n",
    "if debug:\n",
    "    if first_tiff:\n",
    "        print(f\"rawframe {t} (or tiff {first_tiff+t}) to visualize\")      \n",
    "else:\n",
    "    print(f\"rawframe {t} to visualize \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.subplot(121)\n",
    "# Plot the histogram of the pixel intensity values of the rawframe\n",
    "plt.hist(rawframes[t].ravel(), bins=256, log=True)\n",
    "plt.xlim(0, 260) # xlim for 8 bits image\n",
    "\n",
    "plt.subplot(122)\n",
    "# Adjust the color limit for the rawframe for vizualisation only\n",
    "# color = (0,150) # 0<=color<=255 for 8 bits image\n",
    "color = None \n",
    "plt.imshow(rawframes[t],clim = color)\n",
    "plt.colorbar(orientation='horizontal');\n",
    "\n",
    "# plt.savefig(os.path.join(outPath,f'{today}_{movieID}_px_hist_{t}.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show the mask and detected objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "plt.figure(figsize=(18,14))\n",
    "plt.subplot(121)\n",
    "# Show the rawframe\n",
    "plt.imshow(rawframes[t],clim= color)#+lawn)\n",
    "if lawnfile is not None:\n",
    "    # Show the lawn\n",
    "    plt.contour(binLawn, alpha=0.5, cmap='pink')\n",
    "    \n",
    "plt.subplot(122)\n",
    "# Show the masks and their size [px]\n",
    "plt.imshow(masks[t])#[:600,1000:])#[500:1500,2000:3500])#[:,2500:])\n",
    "# print(np.min(masks[t]))\n",
    "label_image, num = label(masks[t], background=0, connectivity = 1,return_num=True)\n",
    "print(f\"{num} detected objects\")\n",
    "for region in regionprops(label_image):\n",
    "    plt.text(region.centroid[1]+50, region.centroid[0], region.area, color ='w')\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "# if not debug:\n",
    "#     plt.title(f\"Rawframe and masks (#{num}) at t={t} ({movieID})\",fontsize=24)\n",
    "#     plt.savefig(os.path.join(outPath,f'{today}_{movieID}_masks_rawframe{t}.pdf'))\n",
    "# if debug:\n",
    "#     plt.title(f\"Rawframe and masks (#{num}) at tiff {first_tiff+t} OR rawframe {t} ({movieID})\", fontsize=24)\n",
    "#     plt.savefig(os.path.join(outPath,f'{today}_{movieID}_masks_tiff{first_tiff+t}.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting individual objects and tracking or use multiprocessing to speed up feature detection\n",
    "\n",
    "This section will go through all frames and find worm-sized (as specified by the parameters) objects. It creates a pd.Dataframe containing these and a stack of images (numpy array) that contain a cropped area around each worm. Note: Each worm image will be length x length x 8bit. So with 30 worms per image you expect the image array to be 6Gb/10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "logger.info('Detecting features...')\n",
    "logger.info(f'...with {nWorkers} workers')\n",
    "objects, images = util.parallel_analysis((masks, rawframes), param, tracking.parallelWorker, framenumbers = None, nWorkers = nWorkers, output= None)\n",
    "# create a link between image and dataframe\n",
    "objects['im_idx'] = np.arange(len(objects))\n",
    "stop = timeit.default_timer()\n",
    "logger.info(f\"features detected ({stop - start}s)\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files monitoring\n",
    "logger.info(f\" Number of frames in features:{objects['frame'].nunique()}\")\n",
    "                                                       \n",
    "if len(rawframes) != len(objects['frame'].unique()):\n",
    "    logger.warning(f\" Number of frames in features ({objects['frame'].nunique()}) and the number of rawframes ({len(rawframes)}) don't match !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize results of object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show the area of all objects\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "objects['area'].hist(bins = 30)\n",
    "plt.xlabel('Area (px)')\n",
    "plt.subplot(122)\n",
    "objects['frame'].value_counts().sort_index().plot()\n",
    "plt.ylabel('Number of objects')\n",
    "plt.xlabel('Frame')\n",
    "#features['frame'].hist(bins = len(rawframes))\n",
    "\n",
    "logger.info(f\"features.area.min():{objects.area.min()}\") # region.area > params['minSize']\n",
    "logger.info(f\"features.area.max():{objects.area.max()}\") # region.area < params['maxSize']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save features and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "# saving features\n",
    "logger.info(\"Saving features...\")\n",
    "objects.info(memory_usage='deep')\n",
    "objects.to_json(outfile.format('features', 'all'), orient='split')\n",
    "stop = timeit.default_timer()\n",
    "logger.info(f\"features saved as {outfile.format('features', 'all')} ({stop - start}s)\")\n",
    "\n",
    "start = timeit.default_timer()\n",
    "# saving images\n",
    "imsave(imfile.format('images', 'all'), images)\n",
    "stop = timeit.default_timer()\n",
    "logger.info(f\"images saved as {imfile.format('images', 'all')} ({stop - start}s)\")\n",
    "\n",
    "# saving parameter file\n",
    "logger.info(\"Saving parameters...\")\n",
    "shutil.copyfile(parameterfile, saveparam, follow_symlinks=True)\n",
    "logger.info(f\"parameters saved as {parameterfile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Load features and images if continuing prior analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if debug:\n",
    "    # Load feature\n",
    "    start = timeit.default_timer()\n",
    "    logger.info(\"Loading features...\")\n",
    "    objects = io.load(outfile.format('features', 'all'), orient='split')\n",
    "    images = pims.open(imfile.format('images', 'all'))\n",
    "    stop = timeit.default_timer()\n",
    "    logger.info(f\"features loaded ({stop - start}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link objects to trajectories using trackpy and interpolate short misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Linking trajectories...')\n",
    "logger.info(f\"Parameter searchRange: {param['searchRange']} px\")\n",
    "logger.info(f\"Parameter memory: {param['memory']} frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = tp.predict.NearestVelocityPredict()\n",
    "#trajectories = pred.link_df(features,param['searchRange'], memory = param['memory'])\n",
    "trajectories = tp.link_df(objects,param['searchRange'], memory = param['memory'])\n",
    "logger.info(f\"Number of trajectories after linking: {len(trajectories['particle'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the variable features to save memory\n",
    "del objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    plt.figure(figsize=(8,8))\n",
    "    tp.plot_traj(trajectories, colorby = 'particle', superimpose=1-masks[t],label=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Filtering out trajectories which last less than the minimal duration ({param['minimalDuration']} frames)...\")\n",
    "logger.info(f\"Nb of trajectories before filtering: {trajectories['particle'].nunique()}\")\n",
    "\n",
    "trajectories = tp.filter_stubs(trajectories,param['minimalDuration'])\n",
    "logger.info(f\"Nb of trajectories after filtering: {trajectories['particle'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save individual trajectories & add the missing images to interpolated trajectories\n",
    "\n",
    "Here we do multiple things: Add missing rows to the trajectory, create a separate image stack for each animal and save the trajectories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract lawn info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inside(x,y,binLawn):\n",
    "    return binLawn[int(y), int(x)]\n",
    "\n",
    "if lawnfile is not None:\n",
    "    trajectories['inside'] = trajectories.apply(\\\n",
    "        lambda row: pd.Series(inside(row['x'], row['y'], binLawn)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Saving {trajectories['particle'].nunique()} trajectories to separate files...\")\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "for particle_index in trajectories['particle'].unique():\n",
    "    tmp = trajectories[trajectories.loc[:,'particle'] == particle_index].copy()\n",
    "    ims = images[tmp['im_idx']]\n",
    "    ims = np.array(ims, dtype = 'uint8')\n",
    "    # generate an interpolated trajectory where all frames are accounted for\n",
    "    traj_interp, ims_interp = tracking.interpolate_helper(rawframes, ims, tmp, param)\n",
    "    # save the new single worm movie\n",
    "    imsave(imfile.format('images', particle_index), np.array(ims_interp, dtype='uint8'))\n",
    "    # save the trajectory\n",
    "    traj_interp.to_json(outfile.format('trajectories', int(particle_index)), orient='split')\n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "logger.info(f\"trajectories saved as json files ({stop - start}s)\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check slow-down before continuing analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lawnfile is not None:\n",
    "    plt.figure(figsize=(12,8))\n",
    "    vcut = []\n",
    "    dt = 1000\n",
    "    for pid in trajectories['particle'].unique():\n",
    "        tmp = trajectories[['frame', 'x', 'y']][trajectories.loc[:,'particle'] == pid].diff()\n",
    "        f = (trajectories[['inside']][trajectories.loc[:,'particle'] == pid]).mean().values\n",
    "        if f<0.9 and f>0.01:\n",
    "            t0 = np.where((trajectories[['inside']][trajectories.loc[:,'particle'] == pid])==1)[0][0]\n",
    "            print('t0:', t0)\n",
    "            try:\n",
    "                if t0>dt:\n",
    "                    print('pid:', pid)\n",
    "                    time = np.linspace(0,2*dt/30., 2*dt)\n",
    "                    #print('time:', len(time))\n",
    "                    v = np.sqrt((tmp['x']**2+tmp['y']**2))/tmp['frame']*30*2.4\n",
    "                    #print('v:', v)\n",
    "                    #print('v.iloc:', v.iloc[t0-dt:t0+dt])\n",
    "                    plt.plot(time, v.iloc[t0-dt:t0+dt], 'navy', alpha=0.1)\n",
    "                    vcut.append(v.iloc[t0-dt:t0+dt].values)\n",
    "                else:\n",
    "                    print('trajectory is too short')\n",
    "            except ValueError:\n",
    "                print('t0-dt or t0+dt exceeds number of frames')\n",
    "                continue\n",
    "                    \n",
    "    if len(vcut) >0:  \n",
    "        plt.plot(time, np.mean(np.array(vcut), axis=0), color='navy')\n",
    "        plt.plot(time, util.smooth(np.mean(np.array(vcut), axis=0), 30), color='r')\n",
    "        plt.axvline(dt/30, color='k', linestyle='--')\n",
    "        plt.ylabel(r\"velocity ($\\mu$m/s)\");\n",
    "        plt.xlabel(\"time (s)\");\n",
    "        plt.ylim(0,150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the whole pharaglow feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "lawnfile = None\n",
    "# save only minimal outputs - reduces save by approx factor 3\n",
    "save_minimal = True\n",
    "path = os.path.dirname(outfile)\n",
    "\n",
    "# analyze all trajectories\n",
    "for fn in os.listdir(path):\n",
    "    file = os.path.join(path,fn)\n",
    "    \n",
    "    if os.path.isfile(file) and f'{movieID}_trajectories_' in fn and fn.endswith('.json'):\n",
    "        particle_index = int(fn.split('.')[0].split('_')[-1])\n",
    "        traj =  io.load(file, orient='split')\n",
    "        # load images\n",
    "        images = pims.open(imfile.format('images', particle_index))\n",
    "        if len(traj.index)<1:\n",
    "            print('Skipped', file)\n",
    "            continue\n",
    "      \n",
    "        print('Analyzing trajectory:', fn)\n",
    "        tmp,_ = util.parallel_analysis((images,), param,\\\n",
    "                          parallelWorker= run.parallel_pharaglow_run, framenumbers = traj['frame'], nWorkers = nWorkers, output= None)\n",
    "       \n",
    "       \n",
    "        # remove some columns to make the result smaller\n",
    "        if save_minimal:\n",
    "            tmp = tmp.drop(['Mask', 'SkeletonX', 'SkeletonY', 'ParX', 'ParY', \n",
    "                            'Xstart', 'Xend', 'Centerline', 'dCl', 'Widths', 'Contour', 'Gradient', \n",
    "                            'Kymo', 'KymoGrad', 'Similarity', 'Xtmp'], axis = 1, errors = 'ignore')\n",
    "        # add the basic tracker info - you can also keep these as separate files\n",
    "        tmp = tmp.merge(traj, on='frame', how = 'outer')\n",
    "        # run some stuff on the whole dataframe.\n",
    "        run.pharynxorientation(tmp)\n",
    "        # extract pumps\n",
    "        tmp[['pumps']] = tmp.apply(\\\n",
    "        lambda row: pd.Series(features.extractPump(row['Straightened'])), axis=1)\n",
    "        # get more exact entry location\n",
    "        if lawnfile is not None:\n",
    "            tmp['insideHead'] = tmp.apply(\\\n",
    "                lambda row: pd.Series(features.headLocationLawn(row['Centerline'],row['slice'], binLawn)), axis=1)\n",
    "            tmp['insideHeadIntensity'] = tmp.apply(\\\n",
    "                lambda row: pd.Series(features.headLocationLawn(row['Centerline'],row['slice'], lawn)), axis=1)\n",
    "        \n",
    "        tmp.to_json(outfile.format('results', particle_index), orient='split')\n",
    "        \n",
    "if save_minimal:\n",
    "    logger.info('minimal information saved')\n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "logger.info(f\"Whole pharaglow features extracted ({stop - start}s)\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if data has been analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files monitoring\n",
    "files_list = os.listdir(outPath)\n",
    "f1 =[]\n",
    "f2 =[]\n",
    "\n",
    "path = os.path.dirname(outfile)\n",
    "\n",
    "for fn in files_list:\n",
    "    file = os.path.join(path,fn)\n",
    "    if os.path.isfile(file) and f'{movieID}_trajectories_' in fn  and fn.endswith('.json'):\n",
    "        if not 'all' in fn: \n",
    "            particle_index = int(fn.split('.')[0].split('_')[-1])\n",
    "            f1.append(particle_index)\n",
    "    if os.path.isfile(file) and f'{movieID}_results_' in fn and fn.endswith('.json'): \n",
    "        particle_index = int(fn.split('.')[0].split('_')[-1])\n",
    "        f2.append(particle_index)\n",
    "\n",
    "logger.info('trajectories.json files: %s ', len(f1))\n",
    "logger.info('results.json files: %s ', len(f2))\n",
    "if len(f1) != len(f2):\n",
    "    logger.warning('trajectories - results: %s', set(f1).symmetric_difference(set(f2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving parameters if they have been changed (debug mode activated)\n",
    "if debug:\n",
    "    logger.debug(f\"New parameters:{param}\")\n",
    "    paramPath = os.path.join(outPath, movieID + '_parameters_new.txt')\n",
    "    with open(paramPath,'w') as f:\n",
    "         f.write(json.dumps(param)) # use `json.loads` to do the reverse\n",
    "         \n",
    "    logger.debug(f\"New parameters saved as {paramPath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"PharaGlow ends here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
